# AnÃ¡lisis Completo del Flujo - Karpenter Manager Unificado

## âœ… VALIDACIÃ“N: Funcionalidad Completa Mantenida

### 1. **MONITOR (`action: "monitor"`)** 
**âœ… Equivalente a `karpenter-health-monitor`**

#### Funcionalidades:
- âœ… Conecta al cluster EKS usando rol asumido
- âœ… Cuenta nodos total/ready/not-ready
- âœ… Verifica estado de pods de Karpenter (running/ready containers)
- âœ… Calcula porcentaje de salud del cluster
- âœ… Identifica issues especÃ­ficos (cluster_not_active, no_nodes, karpenter_not_ready, etc.)
- âœ… **LÃ“GICA DE ESCALACIÃ“N COMPLETA**:
  - Usa DynamoDB para tracking de fallos (`karpenter-health-status` table)
  - **Primer fallo**: Ejecuta recovery automÃ¡ticamente
  - **Segundo fallo**: Ejecuta secuencia completa (stop services â†’ cleanup â†’ recovery)
  - **Cuando healthy**: Reset contador a 0
- âœ… Publica eventos a EventBridge para alertas
- âœ… Auto-invoca recovery/cleanup segÃºn escalaciÃ³n

#### Casos de Uso:
1. **Monitoreo rutinario** (cada 10 minutos)
2. **DetecciÃ³n de fallos de Karpenter**
3. **EscalaciÃ³n automÃ¡tica de recuperaciÃ³n**
4. **Tracking de fallos persistentes**

---

### 2. **RECOVER (`action: "recover"`)** 
**âœ… Equivalente a `karpenter-recovery` + MEJORA**

#### Funcionalidades:
- âœ… Escala nodegroup a 2 nodos (min=2, max=10, desired=2)
- âœ… **WAIT DE 30 SEGUNDOS** (NUEVA MEJORA)
- âœ… Reinicia deployment de Karpenter con annotation `restartedAt`
- âœ… Retorna update_id para tracking

#### Casos de Uso:
1. **RecuperaciÃ³n automÃ¡tica** (triggered por monitor)
2. **RecuperaciÃ³n manual** (invocaciÃ³n directa)
3. **EscalaciÃ³n de primer nivel** (primer fallo detectado)
4. **Parte de secuencia completa** (segundo fallo)

---

### 3. **CLEANUP (`action: "cleanup"`)** 
**âœ… Equivalente a `karpenter-cleanup`**

#### Funcionalidades:
- âœ… Elimina nodos en estado NotReady/Unknown
- âœ… Remueve finalizers de nodos antes de eliminar
- âœ… Limpia NodeClaims huÃ©rfanos (sin nodo asociado)
- âœ… Remueve finalizers de NodeClaims
- âœ… Retorna lista de recursos limpiados

#### Casos de Uso:
1. **Mantenimiento preventivo** (cada hora)
2. **Limpieza post-fallo** (parte de secuencia de recuperaciÃ³n)
3. **Limpieza manual** (invocaciÃ³n directa)
4. **ResoluciÃ³n de recursos stuck**

---

## ðŸ”„ FLUJOS COMPLETOS

### **Flujo Normal (Healthy)**
```
Monitor (cada 10min) â†’ Cluster OK â†’ Reset failure_count = 0
```

### **Flujo Primer Fallo**
```
Monitor â†’ Karpenter NOT Ready â†’ failure_count = 1 â†’ 
EventBridge Alert â†’ Auto-invoke Recovery â†’ 
Scale NodeGroup â†’ Wait 30s â†’ Restart Karpenter
```

### **Flujo Segundo Fallo (CrÃ­tico)**
```
Monitor â†’ Karpenter STILL NOT Ready â†’ failure_count = 2 â†’ 
EventBridge Alert â†’ Full Recovery Sequence:
1. Invoke stop-start-services (stop)
2. Wait 60 seconds (services shutdown)
3. Invoke Cleanup (synchronous - wait for completion)
4. Wait 30 seconds (cleanup stabilization)  
5. Invoke Recovery (scale + restart)
```

### **Flujo Cleanup Rutinario**
```
Cleanup (cada hora) â†’ Remove NotReady/Unknown nodes â†’ 
Remove orphaned NodeClaims â†’ Return cleaned resources
```

---

## ðŸ“Š CASOS DE USO COMPLETOS

### **Casos de Monitoreo**
1. âœ… Cluster completamente saludable
2. âœ… Algunos nodos NotReady (< threshold)
3. âœ… Karpenter pods no running
4. âœ… Karpenter containers no ready
5. âœ… Cluster no ACTIVE
6. âœ… Sin nodos disponibles
7. âœ… Fallos persistentes (escalaciÃ³n)

### **Casos de Recovery**
8. âœ… NodeGroup con capacidad insuficiente
9. âœ… Karpenter deployment corrupto
10. âœ… Necesidad de restart forzado
11. âœ… Recovery despuÃ©s de cleanup

### **Casos de Cleanup**
12. âœ… Nodos stuck en NotReady
13. âœ… Nodos stuck en Unknown
14. âœ… NodeClaims huÃ©rfanos sin nodo
15. âœ… Finalizers bloqueando eliminaciÃ³n
16. âœ… Recursos zombie post-fallo

---

## ðŸŽ¯ VENTAJAS DE LA UNIFICACIÃ“N

### **Operacionales**
- âœ… **Una sola funciÃ³n** vs 3 separadas
- âœ… **CÃ³digo compartido** (configure_eks_client, get_token)
- âœ… **Auto-orquestaciÃ³n** (monitor invoca recovery/cleanup)
- âœ… **Timeout unificado** (600s para todas las operaciones)

### **Funcionales**
- âœ… **EscalaciÃ³n inteligente** (1er fallo â†’ recovery, 2do fallo â†’ full sequence)
- âœ… **Wait mejorado** (30s entre scaling y restart)
- âœ… **Waits de secuencia completa** (60s post-stop, 30s post-cleanup)
- âœ… **Cleanup sÃ­ncrono** en secuencia crÃ­tica
- âœ… **Logging consistente** (mismo formato para todas las acciones)
- âœ… **Error handling unificado**
- âœ… **Timeout extendido** (900s para secuencia completa)

### **EconÃ³micas**
- âœ… **Menos invocaciones** (una funciÃ³n vs mÃºltiples)
- âœ… **Shared warm-up** (mismas dependencias)
- âœ… **Simplified monitoring** (una funciÃ³n para observar)

---

## âš ï¸ CONSIDERACIONES DE MIGRACIÃ“N

### **EventBridge Rules a Actualizar**
```json
{
  "monitor_rule": {
    "ScheduleExpression": "rate(10 minutes)",
    "Input": "{\"action\":\"monitor\"}"
  },
  "cleanup_rule": {
    "ScheduleExpression": "rate(1 hour)", 
    "Input": "{\"action\":\"cleanup\"}"
  }
}
```

### **Dependencias Externas**
- âœ… DynamoDB table: `karpenter-health-status`
- âœ… Lambda layer: `kubernetes-layer:1`
- âœ… IAM roles: `eks-karpenter-health-check-role`
- âš ï¸ External function: `stop-start-services-function` (debe existir)

---

## ðŸ† CONCLUSIÃ“N

**âœ… EL LAMBDA UNIFICADO MANTIENE 100% DE LA FUNCIONALIDAD ORIGINAL**

- Todas las funciones crÃ­ticas estÃ¡n implementadas
- LÃ³gica de escalaciÃ³n completa preservada
- Mejoras aÃ±adidas (wait de 30s)
- Casos de uso cubiertos completamente
- Flujos de recuperaciÃ³n intactos

**La unificaciÃ³n es exitosa y lista para producciÃ³n.**
